{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b979d1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A weather forecasting model might use yesterday's temperature to predict tommorow's temperature.\n",
    "\n",
    "But could it predict the temperature in New York City if it was trained solely on the daily temperature of Denver? What if it was trained on the temperature of 10 different cities spread across the world? What if these cities were within 50 miles of New York City?\n",
    "\n",
    "In simple situations, it's useful to train an LSTM (Long Short-Term Memory) model on a single time series. By learning what happened in the past, the LSTM model predicts what will happen in the future for a specific situation.\n",
    "\n",
    "This begs the question: How \"specific\" does the situation have to be? In some instances, \"situation\" may refer to the physical location of a signal.\n",
    "\n",
    "Let's take a more tangible example: Let's say I dropped a couple of rocks into a lake and they ripple waves out in different directions. Could I use machine learning to predict the height of the water over time at one location, based on the height of the water at other locations?\n",
    "\n",
    "That's the kind of question I'm trying to answer with this project.\n",
    "\n",
    "## Training an LSTM model on different locations of a 2D wave\n",
    "\n",
    "Previously, I have simulated a 2 dimensional wave interference pattern and saved the raw data in the form of a PyTorch tensor. The raw data includes the signal's value over time at all locations in a limited spacial grid.\n",
    "\n",
    "In this notebook, I train an LSTM model on multiple coordinates of the wave simulation, and then test its prediction against the signal at other coordinates.\n",
    "\n",
    "The LSTM model in question consists of one LSTM layer. Multiple hyperparameters may be adjusted for the model, affecting its results in interesting ways:\n",
    "* signal input size\n",
    "* learning rate\n",
    "* number of layers\n",
    "\n",
    "\n",
    "This project is broken down into the following steps (which will be explained in more detail later):\n",
    "\n",
    "* Split data into training and test data. This done by categorizing each of the signal coordinates as \"test or \"train\".\n",
    "* Prepare data for proper batch training using a \"rolling window\" method. This splits data into inputs and labels.\n",
    "* Create LSTM Neural Network Model and train the model with training signal data.\n",
    "* Test the Model on multiple test signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794f6a3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d5a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamq\\anaconda3\\envs\\wavetorch\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "#Import wavetorch module\n",
    "from src import wavetorch\n",
    "\n",
    "#import python libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import random\n",
    "\n",
    "#Visualization libraries\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "\n",
    "#Write Libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470e845",
   "metadata": {},
   "source": [
    "# Configure GPU/CPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f79954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Configure GPU/CPU Usage for Tensor operations\n",
    "\n",
    "#Use GPU if CUDA compatable GPU is available\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)  \n",
    "print(dev)\n",
    "\n",
    "#Set default tensors to be type float\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ab2731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndev=\"cpu\"\\ndevice = torch.device(dev)  \\nprint(dev)\\ntorch.set_default_tensor_type(\\'torch.FloatTensor\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dev=\"cpu\"\n",
    "device = torch.device(dev)  \n",
    "print(dev)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d86052",
   "metadata": {},
   "source": [
    "# Open Raw Data\n",
    "\n",
    "The raw data is stored in the form of a 3 dimensional Torch tensor. The first dimension represents time. The second and the dimensions represent the spacial coordinates x, y respectively.\n",
    "\n",
    "Furthermore, stored metadata is opened, representing time step and spacial step sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d739e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure open paths\n",
    "open_folder = \"exports\"\n",
    "open_path = \"{}\\\\{}\\\\\".format(str(Path.cwd()), open_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1072604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dx': 0.5, 'dy': 0.5, 'dt': 0.006666666666666667, 'c': 30, 'N_t': 2400}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open wave simulation metadata\n",
    "with open(open_path+'data1 metadata.json') as f:\n",
    "    u_metadata=json.load(f)\n",
    "u_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafa95cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0048,  0.0095,  ..., -0.0016, -0.0008,  0.0000],\n",
       "         [ 0.0000,  0.0095,  0.0190,  ..., -0.0027, -0.0016,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0031, -0.0063,  ...,  0.0039,  0.0021,  0.0000],\n",
       "         [ 0.0000, -0.0016, -0.0032,  ...,  0.0020,  0.0010,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0048,  0.0097,  ..., -0.0013, -0.0007,  0.0000],\n",
       "         [ 0.0000,  0.0097,  0.0191,  ..., -0.0020, -0.0011,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0037, -0.0075,  ...,  0.0039,  0.0019,  0.0000],\n",
       "         [ 0.0000, -0.0020, -0.0039,  ...,  0.0019,  0.0010,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0049,  0.0098,  ..., -0.0008, -0.0005,  0.0000],\n",
       "         [ 0.0000,  0.0097,  0.0193,  ..., -0.0012, -0.0005,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0043, -0.0086,  ...,  0.0038,  0.0018,  0.0000],\n",
       "         [ 0.0000, -0.0023, -0.0045,  ...,  0.0018,  0.0009,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open numpy array to torch tensor\n",
    "u_tensor = torch.load(open_path + 'data1.pt')\n",
    "u_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2402, 480, 640])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get dimensions\n",
    "N_t = u_tensor.shape[0]\n",
    "N_x = u_tensor.shape[1]\n",
    "N_y = u_tensor.shape[2]\n",
    "t_array = np.linspace(0, N_t*u_metadata['dt'], N_t)\n",
    "u_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Raw Data and split into training/test data\n",
    "Every possible coordinate (i.e. the signal at each location) is defined from the raw data tensor.\n",
    "\n",
    "After every coordinate is collected into a list, a random assortment of coordinates are taken and put into a Pandas DataFrame, where they are labeled as either \"test\" or \"train\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(370, 242),\n",
       " (26, 351),\n",
       " (277, 496),\n",
       " (390, 353),\n",
       " (117, 228),\n",
       " (54, 404),\n",
       " (347, 126),\n",
       " (137, 175),\n",
       " (354, 61),\n",
       " (95, 286),\n",
       " (173, 153),\n",
       " (144, 2),\n",
       " (357, 515),\n",
       " (140, 561),\n",
       " (271, 220),\n",
       " (334, 130),\n",
       " (169, 273),\n",
       " (337, 579),\n",
       " (17, 210),\n",
       " (479, 156)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a list of all possible coordinates in u_tensor\n",
    "#Initialize list\n",
    "u_tensor_coordinates=[]\n",
    "#Loop through the x and y axes of u_tensor\n",
    "for i in range(0, N_x):\n",
    "    for j in range(0, N_y):\n",
    "        u_tensor_coordinates += [(i,j)]\n",
    "\n",
    "#Take random coordinates\n",
    "u_tensor_coordinates = random.choices(u_tensor_coordinates, k=20)\n",
    "u_tensor_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(370, 242)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(26, 351)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(277, 496)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(390, 353)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 228)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(54, 404)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(347, 126)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(137, 175)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(354, 61)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(95, 286)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(173, 153)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(144, 2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(357, 515)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(140, 561)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(271, 220)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(334, 130)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(169, 273)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(337, 579)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(17, 210)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(479, 156)</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(370, 242), (26, 351), (277, 496), (390, 353), (117, 228), (54, 404), (347, 126), (137, 175), (354, 61), (95, 286), (173, 153), (144, 2), (357, 515), (140, 561), (271, 220), (334, 130), (169, 273), (337, 579), (17, 210), (479, 156)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate dataframe containing coordinates\n",
    "df_coord = wavetorch.generate_labels(u_tensor=u_tensor,\n",
    "                                      source_coordinates=[],\n",
    "                                      loc_coordinates=u_tensor_coordinates)\n",
    "df_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0c21ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(370, 242)</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(26, 351)</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(277, 496)</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(390, 353)</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 228)</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Set\n",
       "(370, 242)  train\n",
       "(26, 351)   train\n",
       "(277, 496)  train\n",
       "(390, 353)  train\n",
       "(117, 228)  train"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split into test and validation sets\n",
    "df_coord['Set'] = np.nan\n",
    "df_coord.loc[df_coord.index[0:5],'Set'] = 'train'\n",
    "df_coord.loc[df_coord.index[15::],'Set']  = 'test'\n",
    "df_coord[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Formatting Training Data\n",
    "\n",
    "A one dimensional signal needs to be properly formatted into an input and an output i.e. \"label\" for an LSTM model to train on it.\n",
    "\n",
    "The function create_dataset generates multiple inputs and outputs per signal through multiple overlapping windows. Roughly speaking, each window has labels indicating what happens in the signal right after the input.\n",
    "\n",
    "With a defined window length \"n_window\", create_dataset iterates through different values of n to extract the input signal between values \"n\" and \"n + n_window\". This is done until the prediction label reaches the end of the signal.\n",
    "\n",
    "For each point within a window, an output signal/label of length \"n_predict\" is generated. Thus, the input data is 2 dimensional and the output data is 3 dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3840a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into multiple signals using a rolling window\n",
    "def create_dataset(data, n_window, n_predict):\n",
    "    #initialize data lists\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    #initialize data\n",
    "    for n in range(0, len(data)-n_window-n_predict):\n",
    "        #Get training data\n",
    "        x = data[n:n+n_window]\n",
    "        y = []\n",
    "        #Define y label of length n_predict based on x\n",
    "        for m in range(0, n_window):\n",
    "            y += [data[n+m+1:n+m+1+n_predict]]\n",
    "        #append training data and label to final format\n",
    "        data_x += [x]\n",
    "        data_y += [y]\n",
    "    data_x = torch.Tensor(data_x).detach().unsqueeze(dim=2)\n",
    "    data_y = torch.Tensor(np.array(data_y)).detach()\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50134e",
   "metadata": {},
   "source": [
    "# Define LSTM Model\n",
    "\n",
    "In PyTorch, neural networks are objects and can be defined as classes. The LSTM class is created with the attributes defined as class arguments:\n",
    "\n",
    "* Input size is the size of the signal to be trained on\n",
    "* Hidden size is the size of the hidden layer in the LSTM\n",
    "* Output size is the size of the predicted signal\n",
    "\n",
    "Furthermore, the activation function is defined (in this case a linear function).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e7c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create neural network class\n",
    "class ModelLSTM(torch.nn.Module):\n",
    "    \n",
    "    #create neural network\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ModelLSTM, self).__init__()\n",
    "        \n",
    "        #set parameters\n",
    "        #batch size ie signal size\n",
    "        self.input_size = input_size\n",
    "        #hidden layer size\n",
    "        self.hidden_size = hidden_size\n",
    "        #output size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #LSTM layer 1\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=3,\n",
    "            batch_first=True, dropout=0.4)\n",
    "        self.linear = torch.nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        \n",
    "    #activation\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(input=x)\n",
    "        # extract only the last time step\n",
    "        out = self.linear(lstm_out)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training Process\n",
    "\n",
    "Once an LSTM model is created, it needs to be trained systematically on the data. This is the purpose of the train_LSTM function.\n",
    "\n",
    "Before training is done, there are some initial steps in the function:\n",
    "\n",
    "* Invoke the previous create_dataset() function to generate training inputs (\"X_train\") and training labels (\"y_train\") from the raw data.\n",
    "* Format the training data into a PyTorch DataLoader object. The main thing to note about the DataLoader is that it shuffles the training data with the argument shuffle=True.\n",
    "* Define the loss function and the optimizer that will train the model according to the loss .\n",
    "\n",
    "Then, the LSTM model is trained on the DataLoader through a predetermined number of epochs. After the loss is initialized (for training performance tracking), the training process iterates through each batch in the DataLoader with the following steps:\n",
    "\n",
    "* Set the gradient to 0.\n",
    "* Make a prediction. (How will the training time series look next?)\n",
    "* Compute the loss between the prediction \"y_pred\" and the DataLoader's actual training label \"y_batch\".\n",
    "* Append the batch's loss the the epoch's running loss.\n",
    "* Backpropagate the neural network using the loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a8e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for training neural network\n",
    "\n",
    "def train_LSTM(LSTM, data, n_window, n_predict, batch_size, learning_rate, momentum, n_epoch, coord, sample, list_loss, n_skip):\n",
    "    \n",
    "    #initialize data train as input\n",
    "    X_train, y_train = create_dataset(data=data, n_window=n_window, n_predict=n_predict)\n",
    "    #initialize torch's dataloader module to format training data\n",
    "    loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size,\n",
    "                                         generator=torch.Generator(device='cuda'))\n",
    "    #initialize loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    #initialize learning method\n",
    "    optimizer = optim.SGD(LSTM.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    #train entire batch of data n_epoch times\n",
    "    for n in range (0, n_epoch):\n",
    "        \n",
    "        #Initialize loss for the epoch\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "        #iterate through each windowed signal and i\n",
    "        #ts label\n",
    "        for X_batch, y_batch in loader:\n",
    "\n",
    "            #Clear cache memory between each batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            LSTM.train()\n",
    "            #set gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #get prediction x_train\n",
    "            y_pred = LSTM(X_batch)\n",
    "            #get loss function calculation (residual)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            #append loss to loss array/list\n",
    "            running_loss += loss.item()\n",
    "            #backpropagate\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #increase batch_count by 1\n",
    "            batch_count += 1\n",
    "\n",
    "            #delete objects out of memory\n",
    "            del y_pred\n",
    "        \n",
    "        list_loss += [running_loss/batch_count]\n",
    "\n",
    "        pred_train = LSTM(X_train)\n",
    "        #plot result against the original time series\n",
    "        plt.figure()\n",
    "        plt.plot(t_array[n_skip::], data, label='actual data')\n",
    "        plt.plot(t_array[n_window+n_skip+n_predict:n_window+n_skip+n_predict+pred_train.shape[0]], pred_train[:, -1, -1].cpu().detach().numpy(), 'g-', label='predictions')\n",
    "        plt.title('LSTM with window length {}; Learning Rate {}; Sample {}; Coordinate {}; Epoch {}; Epoch Count {}'.format(str(n_window), str(learning_rate), str(sample), str(coord),str(n), str(n_epoch)),\n",
    "                                                                                                                            wrap=True)\n",
    "        plt.legend()\n",
    "        filename='train_window{}lr{}sample{}coord{}epoch{}epoch_count{}.png'.format(str(n_window), str(learning_rate), str(sample), str(coord),str(n),\n",
    "                                                                                  str(n_epoch))\n",
    "        save_path=\"{}\\\\exports\\\\plots\\\\train_plots\\\\{}\".format(str(Path.cwd()), filename)\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    return LSTM, list_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LSTMs and Train them\n",
    "\n",
    "The training processes are now applied with set hyperparameters, such as learning rate, number of epochs, etc.\n",
    "\n",
    "Several things to note:\n",
    "* I opt for a specific prediction length \"n_predict\". This well determine how many time series into the future the time series predicts.\n",
    "* I decide to iterate through a list of different window lengths for training to see the difference in effects.\n",
    "\n",
    "After an LSTM is created and trained with the previously defined functions, they are appended to a list for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e19bfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lists of hyperparameters\n",
    "#window size list\n",
    "list_n_window = [200, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63aee04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with window length 200\n",
      "training coordinate 0 out of 5\n",
      "training coordinate 1 out of 5\n",
      "training coordinate 2 out of 5\n",
      "training coordinate 3 out of 5\n",
      "training coordinate 4 out of 5\n"
     ]
    }
   ],
   "source": [
    "#initialize list to get models\n",
    "list_LSTM = []\n",
    "#Set hyperparameters\n",
    "learning_rate = 0.05\n",
    "n_epoch=15\n",
    "n_predict=200\n",
    "hidden_size=50\n",
    "batch_size=1\n",
    "#Skip the first n_skip # of samples because often the signal is at 0 for the first few samples\n",
    "n_skip = 500\n",
    "\n",
    "\n",
    "#loop through hyperparameters\n",
    "for n_window in list_n_window:\n",
    "    \n",
    "    #initialize neural network\n",
    "    LSTM = ModelLSTM(input_size=1, hidden_size=hidden_size, output_size=n_predict)\n",
    "\n",
    "    #initialize list of loss values (for plotting over time)\n",
    "    list_loss = []\n",
    "\n",
    "    #Message\n",
    "    print('Training LSTM with window length {}'.format(str(n_window)))\n",
    "    #loop through each training data point\n",
    "    for n in range(0, len(df_coord[df_coord['Set']=='train'].index)):\n",
    "        \n",
    "        list_loss_coord = []\n",
    "\n",
    "        print('training coordinate {} out of {}'.format(str(n), str(len(df_coord[df_coord['Set']=='train'].index))))\n",
    "        #Extract coordinate of data from index\n",
    "        coord = df_coord[df_coord['Set']=='train'].index[n]\n",
    "        #Use coordinate to get data\n",
    "        ts = u_tensor[:,coord[0], coord[1]]\n",
    "        #Skip the first n_skip # of smaples\n",
    "        ts = ts[n_skip::]\n",
    "        #convert from torch tensor to numpy array\n",
    "        ts = ts.cpu().numpy()\n",
    "        #Set LSTM\n",
    "        LSTM, list_loss_coord = train_LSTM(LSTM=LSTM, data=ts, n_window=n_window, n_predict=n_predict, batch_size=batch_size, learning_rate=learning_rate, momentum=0.9, n_epoch=n_epoch, coord=coord, sample=n,\n",
    "                          list_loss=list_loss_coord, n_skip=n_skip)\n",
    "        \n",
    "        list_loss += list_loss_coord\n",
    "\n",
    "        #Plot loss just for the coordinate\n",
    "        plt.figure()\n",
    "        plt.plot(list_loss_coord)\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.title('Average Loss per Epoch for Coordinate {} (Sample {}): Window length {}; Learning Rate {}; Epoch Count {}'.format(str(coord), str(n), str(n_window), str(learning_rate), str(n_epoch)),\n",
    "                  wrap=True)\n",
    "        filename='training_loss_sample{}_coord{}_window{}lr{}n_epoch{}.png'.format(str(n), str(coord), str(n_window), str(learning_rate), str(n_epoch))\n",
    "        save_path=\"{}\\\\exports\\\\plots\\\\training_loss_plots\\\\{}\".format(str(Path.cwd()), filename)\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    #Plot loss over time\n",
    "    plt.figure()\n",
    "    plt.plot(list_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Average Loss per Epoch: Window length {}; Learning Rate {}; {} Epochs per Coordinate'.format(str(n_window), str(learning_rate), str(n_epoch)), wrap=True)\n",
    "    filename='training_loss_window{}lr{}n_epoch{}.png'.format(str(n_window), str(learning_rate), str(n_epoch))\n",
    "    save_path=\"{}\\\\exports\\\\plots\\\\training_loss_plots\\\\{}\".format(str(Path.cwd()), filename)\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    #append LSTM to list\n",
    "    list_LSTM += [LSTM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5e434",
   "metadata": {},
   "source": [
    "# Test LSTM on Test Set\n",
    "\n",
    "Recall that previously a hold-out \"test set\" of coordinates for the signal was defined. These are locations of the wave simulation that an LSTM is not trained on.\n",
    "\n",
    "This is essentially like seeing if we can predict the temperature of Denver after developing algorithms off of New York and Los Angeles's weather.\n",
    "\n",
    "For each testing process (for a particular LSTM, set of hyperparameters, and location) the following happens:\n",
    "\n",
    "* The signal is extracted from the wave simulation and the specified coordinate\n",
    "* Several signal components are used:\n",
    "    * The actual signal for test comparison. This includes the first portion used to predict the signal in \"future time\", as well as how the signal actually looks in \"future time\".\n",
    "    * Just the first portion used to predict the signal, ie the test input.\n",
    "* Format the test input for prediction.\n",
    "* Get the prediction off of the input using the LSTM model.\n",
    "* Plot the actual signal and the prediction for comparison.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32e3857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window length 200; Predicting test signal 0 out of 5\n",
      "Window length 200; Predicting test signal 1 out of 5\n",
      "Window length 200; Predicting test signal 2 out of 5\n",
      "Window length 200; Predicting test signal 3 out of 5\n",
      "Window length 200; Predicting test signal 4 out of 5\n"
     ]
    }
   ],
   "source": [
    "#Skip the first n_skip # of samples because often the signal is at 0 for the first few samples\n",
    "n_skip = 500\n",
    "\n",
    "#Iterate through each LSTM\n",
    "for m in range(0, len(list_n_window)):\n",
    "    #Get window length\n",
    "    n_window = list_n_window[m]\n",
    "    #Get LSTM\n",
    "    LSTM = list_LSTM[m]\n",
    "    #Iterate through each test coordinate\n",
    "    for n in range(0, len(df_coord[df_coord['Set']=='test'].index)):\n",
    "        LSTM.eval()\n",
    "        print('Window length {}; Predicting test signal {} out of {}'.format(str(n_window), str(n), str(len(df_coord[df_coord['Set']=='test'].index))))\n",
    "        #Get coordinate\n",
    "        coord = df_coord[df_coord['Set']=='test'].index[n]\n",
    "        #Extract signal from torch tensor at coordinate\n",
    "        ts = u_tensor[:,coord[0], coord[1]]\n",
    "        #convert from torch tensor to numpy array\n",
    "        ts = ts.cpu().numpy()\n",
    "\n",
    "        #Get the actual signal from the start (after skipping first n_skip # of samples)\n",
    "        ts_actual = ts[n_skip::]\n",
    "        #Get the initial signal from which to extrapolate predictions\n",
    "        ts_test = ts[n_skip:n_window+n_skip+1]\n",
    "        \n",
    "        #Get test data\n",
    "        X_test = torch.Tensor(ts_test).detach().unsqueeze(dim=1).unsqueeze(dim=0)\n",
    "        #Get prediction\n",
    "        y_pred = LSTM(X_test)[:,-1,:]\n",
    "\n",
    "        #plot prediction\n",
    "        plt.figure()\n",
    "        plt.plot(t_array[n_skip:len(ts_actual)+n_skip], ts_actual, label='actual data')\n",
    "        plt.plot(t_array[n_window+n_skip+1:n_window+n_skip+1+len(y_pred[0])], y_pred[0].cpu().detach().numpy(), label='predicted data')\n",
    "        plt.title('LSTM window length {} Prediction; Learning Rate {}; Test sample {}; Coordinate {}; {} Epochs per Coordinate'.format(str(n_window), str(learning_rate), str(n), str(coord),\n",
    "                                                                                                                                       str(n_epoch)), wrap=True)\n",
    "        plt.legend()\n",
    "        filename='pred_window{}lr{}sample{}coord{}n_epoch{}.png'.format(str(n_window), str(learning_rate), str(n), str(coord), str(n_epoch))\n",
    "        save_path2=\"{}\\\\exports\\\\plots\\\\test_plots\\\\{}\".format(str(Path.cwd()), filename)\n",
    "        plt.savefig(save_path2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
